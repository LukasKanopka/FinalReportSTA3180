---
title: "Used Car Analysis"
author: "Laurynas Kanopka, Jaden Smith, Olivia Caruso, Darina Serik"
date: "2025-04-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(boot)
library(splines)
```

## R Markdown

```{r cars, results='hold'}
# Clean up our data and put it into a new csv file. 
library(dplyr)
library(stringr)
library(readr)

# Read the original dataset
cars_data <- read.csv("used_cars.csv", stringsAsFactors = FALSE)

# Clean the data
cleaned_cars <- cars_data %>%
  mutate(
    # Extract just the numeric part from mileage
    Mileage = as.integer(gsub("[^0-9]", "", milage)),
    
    # Extract horsepower from engine column
    Horsepower = as.integer(str_extract(engine, "\\d+\\.?\\d*(?=HP|hp)")),
    
    # Clean model_year to ensure it's just the year
    Model_year = as.integer(model_year),
    
    # Clean price to extract just the number
    Price = as.integer(gsub("[^0-9]", "", price)),
    
    # Convert accident to binary (0 for none, 1 for everything else that's not null)
    Accident = ifelse(is.na(accident) | accident == "", NA,
                     ifelse(str_detect(accident, "None"), 0, 1)),
    
    # Keep original Brand and Model columns
    Brand = brand,
    Model = model
  ) %>%
  # Select only the columns we want in our final output
  select(Brand, Model, Model_year, Mileage, Horsepower, Accident, Price)

# Save the cleaned data to a new CSV file
write.csv(cleaned_cars, "cleaned_cars.csv", row.names = FALSE)

# Preview the first few rows of the cleaned data
head(cleaned_cars)
```

```{r no_null, results='hold'}
# Create a version with no null values

# Read the cleaned data
# We could use the cleaned_cars object directly, but reading from file ensures this chunk can run independently
cleaned_cars <- read.csv("cleaned_cars.csv", stringsAsFactors = FALSE)

# Remove rows with any NA values
cleaned_cars_no_null <- cleaned_cars %>%
  na.omit()

# Save to a new CSV file
write.csv(cleaned_cars_no_null, "cleaned_cars_no_null.csv", row.names = FALSE)

# Show how many rows were removed
cat("Original number of rows:", nrow(cleaned_cars), "\n")
cat("Number of rows after removing nulls:", nrow(cleaned_cars_no_null), "\n")
cat("Number of rows removed:", nrow(cleaned_cars) - nrow(cleaned_cars_no_null), "\n")

# Preview the first few rows
head(cleaned_cars_no_null)

#cat(nrow(cleaned_cars_no_null))
```

```{r data_prep, results='hold'}
car_data <- read.csv("cleaned_cars_no_null.csv")
attach(car_data)

# Convert Accident to factor
car_data$Accident <- factor(car_data$Accident)

# Summary statistics
summary(car_data[,c("Price","Mileage","Horsepower")])
```


```{r multiple_linear_regression, results='hold'}

# Standard model
mod_std <- lm(Price ~ Mileage + Horsepower + Accident + Model_year, data=car_data)
summary(mod_std)

# Log-transformed model
mod_log <- lm(log(Price) ~ Mileage + Horsepower + Accident + Model_year, data=car_data)
summary(mod_log)

# Residual diagnostics for standard model
par(mfrow=c(2,2))
plot(mod_std, pch=16, cex=0.4, col="black")
par(mfrow=c(1,1))


# Residual diagnostics for log-transformed model
par(mfrow=c(2,2))
plot(mod_log, pch=16, cex=0.4, col="royalblue")
par(mfrow=c(1,1))

```



```{r polynomial_regression, results='hold'}

set.seed(3180)
cv.err <- rep(0,5)
for (i in 1:5) {
  glm.fit <- glm(Price ~ poly(Mileage,i) + poly(Horsepower,i) + Accident + Model_year, 
                data=car_data)
  cv.err[i] <- cv.glm(car_data, glm.fit, K=20)$delta[1]
}
plot(1:5, cv.err, type="b", col="seagreen", xlab="Polynomial Degree", 
     main="20-Fold CV Error for Polynomial Terms")

# Fit optimal degree (example: 2)
mod_poly <- lm(Price ~ poly(Mileage,2) + poly(Horsepower,2) + Accident + Model_year, 
               data=car_data)
summary(mod_poly)

# Residual diagnostics for log-transformed model
par(mfrow=c(2,2))
plot(mod_poly, pch=16, cex=0.4, col="seagreen")
par(mfrow=c(1,1))


```





```{r bootstrap, results='hold'}

alpha.fn <- function(data, index) {
  coef(lm(Price ~ Mileage + Horsepower + Accident + Model_year, 
          data=data, subset=index))[2]  # Focus on Mileage ONLY
}

set.seed(123)
boot.res <- boot(car_data, alpha.fn, R=1000)

# Use percentile method instead of bca
boot.ci(boot.res, type="perc", index=1)  

# Plot bootstrap distribution
hist(boot.res$t, breaks=30, col="orange", 
     main="Bootstrap Distribution of Mileage Coefficient",
     xlab="Coefficient Value")
abline(v=boot.res$t0, col="black", lwd=2)
```



```{r model_comparison, results='hold'}

# Function to calculate metrics
calc_metrics <- function(model, data) {
  pred <- predict(model, data)
  residuals <- data$Price - pred
  rmse <- sqrt(mean(residuals^2))
  mae <- mean(abs(residuals))
  r2 <- summary(model)$r.squared
  return(c(RMSE=rmse, MAE=mae, R2=r2))
}

metrics <- rbind(
  Standard = calc_metrics(mod_std, car_data),
  Log_Transformed = calc_metrics(mod_log, car_data),
  Polynomial = calc_metrics(mod_poly, car_data)
)
print(metrics)

```

```{r random_forest}
library(randomForest)

set.seed(3180) 
rf.fit <- randomForest(Price ~ Mileage + Horsepower + Accident + Model_year,
                       data=car_data,
                       importance=TRUE,
                       ntree=500)

# Variable importance plot
varImpPlot(rf.fit, pch=16, col="blue", 
           main="Variable Importance in Random Forest")

# Get predictions and calculate metrics
rf.pred <- predict(rf.fit, car_data)
rf.resid <- car_data$Price - rf.pred

# Add to model comparison table
rfmetrics <- rbind(
  metrics,
  Random_Forest = c(
    RMSE = sqrt(mean(rf.resid^2)),
    MAE = mean(abs(rf.resid)),
    R2 = cor(car_data$Price, rf.pred)^2  # Pseudo R^2
  )
)

# Update comparison table
print(rfmetrics)

```

```{r decision_tree, results='hold'}

library(rpart)
tree.mod <- rpart(Price ~ Mileage + Horsepower + Accident + Model_year, 
                  data=car_data, method="anova")
plot(tree.mod, uniform=TRUE, margin=0.1)
text(tree.mod, cex=0.7)

```

```{r final_table, results='hold'}

# Predicted vs Actual
par(mfrow=c(1,2))
plot(predict(mod_std), car_data$Price, pch=16, col="blue", 
     main="Standard Model: Pred vs Actual")
abline(0,1, col="red")

plot(predict(mod_poly), car_data$Price, pch=16, col="green3", 
     main="Poly Model: Pred vs Actual")
abline(0,1, col="red")
par(mfrow=c(1,1))

```






